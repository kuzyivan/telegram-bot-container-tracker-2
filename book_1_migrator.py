# book_1_migrator.py
import asyncio
import os
import glob
import pandas as pd
import re
import logging
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlalchemy import text
from dotenv import load_dotenv

# –ü–æ–¥–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
from models import RailwaySection
from db_base import Base 

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()
# –í–ê–ñ–ù–û: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ .env —Ñ–∞–π–ª–µ –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è TARIFF_DATABASE_URL
# –ü—Ä–∏–º–µ—Ä: TARIFF_DATABASE_URL=postgresql+asyncpg://user:pass@localhost/tariff_db
TARIFF_DB_URL = os.getenv("TARIFF_DATABASE_URL")

DATA_DIR = "zdtarif_bot/data" # –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª–∞–º

async def migrate_book_1():
    if not TARIFF_DB_URL:
        logger.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è TARIFF_DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª.")
        return

    engine = create_async_engine(TARIFF_DB_URL, echo=False)
    
    # 1. –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É (–µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    async with engine.begin() as conn:
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã {RailwaySection.__tablename__}...")
        await conn.run_sync(Base.metadata.create_all, tables=[RailwaySection.__table__])
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
        logger.info(f"–û—á–∏—Å—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã {RailwaySection.__tablename__}...")
        await conn.execute(text(f"TRUNCATE TABLE {RailwaySection.__tablename__} RESTART IDENTITY CASCADE"))

    Session = async_sessionmaker(engine, expire_on_commit=False)

    # 2. –ò—â–µ–º —Ñ–∞–π–ª—ã –ö–Ω–∏–≥–∏ 1
    files = sorted(glob.glob(os.path.join(DATA_DIR, "1-*.csv")))
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ö–Ω–∏–≥–∏ 1: {len(files)}")

    for filepath in files:
        filename = os.path.basename(filepath)
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pandas –¥–ª—è —á—Ç–µ–Ω–∏—è CSV.
            # skiprows=5 - —ç—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ, –≤–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–∏–¥–µ—Ç—Å—è –ø–æ–¥–æ–±—Ä–∞—Ç—å.
            # encoding='cp1251' - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∂/–¥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
            df = pd.read_csv(filepath, skiprows=5, encoding='cp1251', header=None, dtype=str, on_bad_lines='warn')
            
            current_section_stations = []
            sections_to_save = []
            
            for index, row in df.iterrows():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –º–µ–Ω—å—à–µ 3 –∫–æ–ª–æ–Ω–æ–∫
                if len(row) < 3:
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∏ –∏–º—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (NaN)
                raw_code = str(row[1]).strip() if pd.notna(row[1]) else ""
                raw_name = str(row[2]).strip() if pd.notna(row[2]) else ""
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂ –ª–∏ –∫–æ–¥ –Ω–∞ –∫–æ–¥ —Å—Ç–∞–Ω—Ü–∏–∏ (5 –∏–ª–∏ 6 —Ü–∏—Ñ—Ä)
                if re.fullmatch(r'\d{5,6}', raw_code):
                    station_obj = {
                        "c": raw_code, # 'c' for code
                        "n": raw_name  # 'n' for name
                    }
                    current_section_stations.append(station_obj)
                else:
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Å—Ç–∞–Ω—Ü–∏—é, —ç—Ç–æ —Ä–∞–∑—Ä—ã–≤.
                    # –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º —Å–ø–∏—Å–∫–µ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π —Å—Ç–∞–Ω—Ü–∏–∏, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –∫–∞–∫ —É—á–∞—Å—Ç–æ–∫.
                    if len(current_section_stations) > 1:
                        sections_to_save.append(list(current_section_stations))
                    
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –Ω–æ–≤–æ–≥–æ —É—á–∞—Å—Ç–∫–∞
                    current_section_stations = []
            
            # –ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ –≤ —Å–ø–∏—Å–∫–µ –æ—Å—Ç–∞–ª–∏—Å—å —Å—Ç–∞–Ω—Ü–∏–∏, —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —É—á–∞—Å—Ç–æ–∫
            if len(current_section_stations) > 1:
                sections_to_save.append(current_section_stations)

            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            if sections_to_save:
                async with Session() as session:
                    async with session.begin():
                        for section_list in sections_to_save:
                            # –ü–µ—Ä–≤–∞—è –∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç–∞–Ω—Ü–∏–∏ —É—á–∞—Å—Ç–∫–∞
                            start_node_code = section_list[0]['c']
                            end_node_code = section_list[-1]['c']
                            
                            db_obj = RailwaySection(
                                node_start_code=start_node_code,
                                node_end_code=end_node_code,
                                source_file=filename,
                                stations_list=section_list
                            )
                            session.add(db_obj)
                
                logger.info(f"   -> –ù–∞–π–¥–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(sections_to_save)} —É—á–∞—Å—Ç–∫–æ–≤.")
            else:
                logger.warning(f"   -> –í —Ñ–∞–π–ª–µ {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å—Ç–∞–Ω—Ü–∏–π.")

        except FileNotFoundError:
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename}: {e}")

    await engine.dispose()
    logger.info("üéâ –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ö–Ω–∏–≥–∏ 1 –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    # –î–ª—è –∑–∞–ø—É—Å–∫–∞ —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞:
    # 1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω pandas: pip install pandas
    # 2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Ñ–∞–π–ª–µ .env —É–∫–∞–∑–∞–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è TARIFF_DATABASE_URL
    # 3. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: python book_1_migrator.py
    asyncio.run(migrate_book_1())
