# services/terminal_importer.py
from __future__ import annotations

import logging
import os
import re
import asyncio
import datetime
from datetime import timedelta
from zoneinfo import ZoneInfo
from typing import Optional, Dict, Any, Tuple, List

import pandas as pd
from sqlalchemy import text, update
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.ext.asyncio import AsyncSession

# --- –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞ ---
from db import SessionLocal
from services.imap_service import ImapService
from model.terminal_container import TerminalContainer
# –í–Ω–∏–º–∞–Ω–∏–µ: –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å IMAP –Ω—É–∂–µ–Ω —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –ø–æ–∏—Å–∫–∞
from imap_tools.query import AND

logger = logging.getLogger(__name__)

# --- –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò ---
DOWNLOAD_DIR = "download_container"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞ –ø–∏—Å–µ–º (–∏–∑ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏)
SUBJECT_FILTER_TERMINAL = r'executive\s*summary'
SENDER_FILTER_TERMINAL = 'aterminal@effex.ru'
FILENAME_PATTERN_TERMINAL = r'\.(xlsx|xls)$'

# –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ñ–∞–π–ª–∞ "–ü–æ–µ–∑–¥" (train_importer logic)
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ import_train_from_excel
CLIENT_COLUMN_INDEX = 11  # L-–∫–æ–ª–æ–Ω–∫–∞

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò (HELPER FUNCTIONS) ---

def _get_vladivostok_date_str(days_offset: int = 0) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É –≤–æ –í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì."""
    try:
        tz = ZoneInfo("Asia/Vladivostok")
    except Exception:
        # Fallback
        tz = datetime.timezone(datetime.timedelta(hours=10))
    target_date = datetime.datetime.now(tz) - timedelta(days=days_offset)
    return target_date.strftime("%d.%m.%Y")

def clean_string_value(val: Any) -> Optional[str]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è —á–∏—Å–ª–∞."""
    if pd.isna(val) or val == '' or str(val).lower() == 'nan':
        return None
    try:
        if isinstance(val, float) and val.is_integer():
            return str(int(val))
        if isinstance(val, (int, float)):
            return str(int(val))
    except Exception:
        pass
    return str(val).strip()

def normalize_container(value: Any) -> Optional[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: —É–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–µ–ª—ã, .0, –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
    s = clean_string_value(value)
    if not s:
        return None
    s = s.upper()
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
    s = re.sub(r'[^A-Z0-9]', '', s)
    if len(s) == 11:
        return s
    return s if s else None

def normalize_client_name(value: Any) -> Optional[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏–º—è –∫–ª–∏–µ–Ω—Ç–∞."""
    return clean_string_value(value)

def parse_date_safe(val: Any) -> Optional[datetime.date]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã."""
    if pd.isna(val) or val == '': return None
    try:
        if isinstance(val, pd.Timestamp): return val.date()
        if isinstance(val, datetime.datetime): return val.date()
        if isinstance(val, str): return pd.to_datetime(val, dayfirst=True).date()
    except Exception: return None
    return None

def parse_time_safe(val: Any) -> Optional[datetime.time]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏."""
    if pd.isna(val) or val == '': return None
    try:
        if isinstance(val, pd.Timestamp): return val.time()
        if isinstance(val, datetime.datetime): return val.time()
        if isinstance(val, datetime.time): return val
        if isinstance(val, str):
            # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –≤—Ä–µ–º—è –∏–∑ —Å—Ç—Ä–æ–∫–∏
            return pd.to_datetime(val, dayfirst=True).time()
    except Exception: return None
    return None

def parse_float_safe(val: Any) -> Optional[float]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–∏—Å–ª–∞."""
    if pd.isna(val) or val == '': return None
    try:
        if isinstance(val, (int, float)): return float(val)
        clean_val = str(val).replace(',', '.').replace('\xa0', '').strip()
        return float(clean_val)
    except Exception: return None

def extract_train_code_from_filename(filename: str) -> str | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–¥ –ø–æ–µ–∑–¥–∞ (–ö25-...) –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    if not filename: return None
    base = os.path.basename(filename)
    name, _ = os.path.splitext(base)
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω KXX-XXX –∏–ª–∏ –öXX-XXX
    m = re.search(r"([–öK]\s*\d{2}[-‚Äì‚Äî ]?\s*\d{3})", name, flags=re.IGNORECASE)
    if not m: return None
    code = m.group(1).upper().replace("K", "–ö").replace(" ", "").replace("‚Äì", "-").replace("‚Äî", "-")
    return code

def find_container_column(df: pd.DataFrame) -> str | None:
    """–ò—â–µ—Ç –∫–æ–ª–æ–Ω–∫—É —Å –Ω–æ–º–µ—Ä–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –≤ DataFrame."""
    candidates = ["–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", "container", "container no", "–Ω–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞", "‚Ññ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"]
    cols_norm = {str(c).strip().lower(): str(c) for c in df.columns}
    for cand in candidates:
        if cand in cols_norm:
            return cols_norm[cand]
    for col in df.columns:
        if "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä" in str(col).lower():
            return str(col)
    return None


# =========================================================================
# 1. –õ–û–ì–ò–ö–ê –î–õ–Ø –ü–õ–ê–ù–ò–†–û–í–©–ò–ö–ê (–ü–†–û–í–ï–†–ö–ê –ü–û–ß–¢–´ –ò –ó–ê–ü–£–°–ö –ò–ú–ü–û–†–¢–ê)
# =========================================================================

async def check_and_process_terminal_report() -> Optional[Dict[str, Any]]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Scheduler.
    1. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –ø–æ—á—Ç–µ.
    2. –ò—â–µ—Ç –ø–∏—Å—å–º–æ —Å Executive summary –∑–∞ —Å–µ–≥–æ–¥–Ω—è (–∏–ª–∏ –≤—á–µ—Ä–∞).
    3. –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª.
    4. –ó–∞–ø—É—Å–∫–∞–µ—Ç process_terminal_report_file –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î.
    """
    imap = ImapService()
    filepath = None
    
    # 1. –ü–æ–∏—Å–∫ –∑–∞ –°–ï–ì–û–î–ù–Ø
    today_str = _get_vladivostok_date_str(days_offset=0)
    logger.info(f"[Terminal Check] –ò—â—É 'Executive summary' –∑–∞ {today_str}...")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä —Ç–µ–º—ã (regex –¥–ª—è imap_service)
    subject_regex_today = fr"{SUBJECT_FILTER_TERMINAL}.*{re.escape(today_str)}"
    
    filepath = await asyncio.to_thread(
        imap.download_latest_attachment,
        subject_filter=subject_regex_today,
        sender_filter=SENDER_FILTER_TERMINAL,
        filename_pattern=FILENAME_PATTERN_TERMINAL
    )

    # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –∑–∞ –í–ß–ï–†–ê
    if not filepath:
        yesterday_str = _get_vladivostok_date_str(days_offset=1)
        logger.info(f"[Terminal Check] –ó–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–µ—Ç. –ò—â—É –∑–∞ –≤—á–µ—Ä–∞ ({yesterday_str})...")
        subject_regex_yesterday = fr"{SUBJECT_FILTER_TERMINAL}.*{re.escape(yesterday_str)}"
        
        filepath = await asyncio.to_thread(
            imap.download_latest_attachment,
            subject_filter=subject_regex_yesterday,
            sender_filter=SENDER_FILTER_TERMINAL,
            filename_pattern=FILENAME_PATTERN_TERMINAL
        )

    if not filepath:
        logger.info("[Terminal Check] –ê–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None

    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞
    stats = None
    try:
        logger.info(f"[Terminal Check] –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {filepath}. –ó–∞–ø—É—Å–∫ –∏–º–ø–æ—Ä—Ç–∞ –≤ –ë–î...")
        
        async with SessionLocal() as session:
            # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–Ω–æ–≤–∞—è –ª–æ–≥–∏–∫–∞)
            await process_terminal_report_file(session, filepath)
            
            # TODO: –ú–æ–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å process_terminal_report_file —á—Ç–æ–±—ã –æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–ª —Å—á–µ—Ç—á–∏–∫–∏
            stats = {
                "file_name": os.path.basename(filepath),
                "status": "success",
                "total_added": "–°–º. –ª–æ–≥–∏" 
            }
            
    except Exception as e:
        logger.error(f"‚ùå [Terminal Check] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}", exc_info=True)
        stats = {"error": str(e)}
    finally:
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if filepath and os.path.exists(filepath):
            os.remove(filepath)
            logger.info(f"[Terminal Check] –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω.")

    return stats


# =========================================================================
# 2. –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –û–¢–ß–ï–¢–ê –¢–ï–†–ú–ò–ù–ê–õ–ê (–ù–û–í–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ë–î)
# =========================================================================

async def process_terminal_report_file(session: AsyncSession, file_path: str):
    """
    –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª A-Terminal.
    –û–∂–∏–¥–∞–µ—Ç –ª–∏—Å—Ç—ã 'Arrival' (–ü—Ä–∏–±—ã—Ç–∏–µ) –∏ 'Dispatch' (–û—Ç–≥—Ä—É–∑–∫–∞).
    """
    logger.info(f"[Import] –ê–Ω–∞–ª–∏–∑ Excel-—Ñ–∞–π–ª–∞: {file_path}")

    try:
        xls = pd.ExcelFile(file_path)
        sheet_names = xls.sheet_names
        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –ª–∏—Å—Ç—ã: {sheet_names}")

        processed_any = False

        # 1. –õ–∏—Å—Ç ARRIVAL
        arrival_sheet = next((s for s in sheet_names if "Arrival" in s), None)
        if arrival_sheet:
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Å—Ç–∞ –ü–†–ò–ë–´–¢–ò–Ø: {arrival_sheet}")
            df_arrival = pd.read_excel(xls, sheet_name=arrival_sheet, dtype=object)
            await _process_arrival_data(session, df_arrival)
            processed_any = True
        else:
            logger.warning("–õ–∏—Å—Ç 'Arrival' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        # 2. –õ–∏—Å—Ç DISPATCH
        dispatch_sheet = next((s for s in sheet_names if "Dispatch" in s), None)
        if dispatch_sheet:
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Å—Ç–∞ –û–¢–ì–†–£–ó–ö–ò: {dispatch_sheet}")
            df_dispatch = pd.read_excel(xls, sheet_name=dispatch_sheet, dtype=object)
            await _process_dispatch_data(session, df_dispatch)
            processed_any = True
        else:
            logger.warning("–õ–∏—Å—Ç 'Dispatch' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        
        # Fallback: –ï—Å–ª–∏ —Å–ø–µ—Ü. –ª–∏—Å—Ç–æ–≤ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–∫ –æ–±—â–∏–π —Å—Ç–æ–∫
        if not processed_any:
            logger.warning("–°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ª–∏—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç –∫–∞–∫ Arrival.")
            df_generic = pd.read_excel(xls, sheet_name=0, dtype=object)
            await _process_arrival_data(session, df_generic)

        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel: {e}", exc_info=True)
        raise e

async def _process_arrival_data(session: AsyncSession, df: pd.DataFrame):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ARRIVAL. –í—ã–ø–æ–ª–Ω—è–µ—Ç UPSERT (–í—Å—Ç–∞–≤–∫–∞ –∏–ª–∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ).
    """
    df.columns = df.columns.str.strip()
    
    # –ú–∞–ø–ø–∏–Ω–≥: Excel Column -> DB Field
    mapping = {
        '–¢–µ—Ä–º–∏–Ω–∞–ª': 'terminal',
        '–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä': 'container_number',
        '–ö–ª–∏–µ–Ω—Ç': 'client',
        '–ò–ù–ù': 'inn',
        '–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 'short_name',
        '–°—Ç–æ–∫': 'stock',
        '–¢–∞–º–æ–∂–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º': 'customs_mode',
        '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ': 'direction',
        '–¢–∏–ø': 'container_type',
        '–†–∞–∑–º–µ—Ä': 'size',
        '–¢–∞—Ä–∞': 'tare',
        '–ë—Ä—É—Ç—Ç–æ –∫–ª–∏–µ–Ω—Ç–∞': 'weight_client', 
        '–°–æ—Å—Ç–æ—è–Ω–∏–µ': 'state',
        '–ì—Ä—É–∑': 'cargo',
        '–ü–ª–æ–º–±—ã': 'seals',
        '–ü—Ä–∏–Ω—è—Ç': 'accept_date',
        # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ –ø–æ–ª—è –≤—Ö–æ–¥–∞
        'Id': 'in_id',
        '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': 'in_transport',
        '–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞ | –ù–æ–º–µ—Ä —Ç—è–≥–∞—á–∞': 'in_number',
        '–°—Ç–∞–Ω—Ü–∏—è | –í–æ–¥–∏—Ç–µ–ª—å': 'in_driver'
    }

    processed_rows = []
    
    for _, row in df.iterrows():
        # –ò—â–µ–º –Ω–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        cont_val = row.get('–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä')
        container_number = normalize_container(cont_val)
        
        if not container_number:
            continue

        data = {}
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        for xls_col, db_col in mapping.items():
            val = row.get(xls_col)
            
            if db_col in ['tare', 'weight_client']:
                data[db_col] = parse_float_safe(val)
            elif db_col == 'accept_date':
                # '–ü—Ä–∏–Ω—è—Ç' –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
                data['accept_date'] = parse_date_safe(val)
                data['accept_time'] = parse_time_safe(val)
            elif db_col == 'container_number':
                continue # –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏
            else:
                data[db_col] = clean_string_value(val)

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∏ –¥–µ—Ñ–æ–ª—Ç—ã
        data['container_number'] = container_number
        if not data.get('terminal'):
            data['terminal'] = 'A-Terminal'
        
        # –°—Ç–∞—Ç—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø—Ä–∏–±—ã–≤—à–∏—Ö
        data['status'] = 'ARRIVED'
        
        processed_rows.append(data)

    if processed_rows:
        await _bulk_upsert_arrival(session, processed_rows)

async def _process_dispatch_data(session: AsyncSession, df: pd.DataFrame):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö DISPATCH. –¢–æ–ª—å–∫–æ UPDATE —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö (–ø—Ä–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–∞—Ç—É —É–±—ã—Ç–∏—è).
    """
    df.columns = df.columns.str.strip()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–∫–∏ –¥–∞—Ç—ã —É–±—ã—Ç–∏—è
    if '–û—Ç–ø—Ä–∞–≤–ª–µ–Ω' not in df.columns:
        logger.warning("–í –ª–∏—Å—Ç–µ Dispatch –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–û—Ç–ø—Ä–∞–≤–ª–µ–Ω'. –ü—Ä–æ–ø—É—Å–∫.")
        return

    processed_rows = []

    for _, row in df.iterrows():
        container_number = normalize_container(row.get('–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä'))
        if not container_number:
            continue

        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        data = {
            'container_number': container_number,
            'status': 'DISPATCHED', # –ú–µ–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å
            'updated_at': datetime.datetime.now()
        }

        # –î–∞—Ç–∞ —É–±—ã—Ç–∏—è
        out_val = row.get('–û—Ç–ø—Ä–∞–≤–ª–µ–Ω')
        data['dispatch_date'] = parse_date_safe(out_val)
        data['dispatch_time'] = parse_time_safe(out_val)

        # –ü–æ–ª—è –≤—ã—Ö–æ–¥–∞ (–æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç —Å—É—Ñ—Ñ–∏–∫—Å .1 –≤ pandas, –µ—Å–ª–∏ –∏–º–µ–Ω–∞ –¥—É–±–ª–∏—Ä—É—é—Ç—Å—è —Å –≤—Ö–æ–¥–æ–º)
        # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã –≤ —Ñ–∞–π–ª–µ, —Å—É—Ñ—Ñ–∏–∫—Å–∞ –Ω–µ –±—É–¥–µ—Ç. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞.
        data['out_id'] = clean_string_value(row.get('Id.1') or row.get('Id'))
        data['out_transport'] = clean_string_value(row.get('–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç.1') or row.get('–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç'))
        data['out_number'] = clean_string_value(row.get('–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞ | –ù–æ–º–µ—Ä —Ç—è–≥–∞—á–∞.1') or row.get('–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞ | –ù–æ–º–µ—Ä —Ç—è–≥–∞—á–∞'))
        data['out_driver'] = clean_string_value(row.get('–°—Ç–∞–Ω—Ü–∏—è | –í–æ–¥–∏—Ç–µ–ª—å.1') or row.get('–°—Ç–∞–Ω—Ü–∏—è | –í–æ–¥–∏—Ç–µ–ª—å'))

        processed_rows.append(data)

    if processed_rows:
        await _bulk_update_dispatch(session, processed_rows)

# --- SQL –ó–ê–ü–†–û–°–´ (RAW) ---

async def _bulk_upsert_arrival(session: AsyncSession, rows: List[dict]):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –º–∞—Å—Å–æ–≤—ã–π INSERT ... ON CONFLICT DO UPDATE –¥–ª—è –ø—Ä–∏–±—ã—Ç–∏—è."""
    if not rows: return
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw SQL –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –≥–∏–±–∫–æ—Å—Ç–∏ upsert
    stmt = text("""
        INSERT INTO terminal_containers (
            terminal, container_number, client, inn, short_name, stock,
            customs_mode, direction, container_type, size, tare, weight_client,
            state, cargo, seals, accept_date, accept_time,
            in_id, in_transport, in_number, in_driver, status, updated_at, created_at
        ) VALUES (
            :terminal, :container_number, :client, :inn, :short_name, :stock,
            :customs_mode, :direction, :container_type, :size, :tare, :weight_client,
            :state, :cargo, :seals, :accept_date, :accept_time,
            :in_id, :in_transport, :in_number, :in_driver, :status, NOW(), NOW()
        )
        ON CONFLICT (container_number) DO UPDATE SET
            terminal = EXCLUDED.terminal,
            client = EXCLUDED.client,
            inn = EXCLUDED.inn,
            short_name = EXCLUDED.short_name,
            stock = EXCLUDED.stock,
            customs_mode = EXCLUDED.customs_mode,
            direction = EXCLUDED.direction,
            container_type = EXCLUDED.container_type,
            size = EXCLUDED.size,
            tare = EXCLUDED.tare,
            weight_client = EXCLUDED.weight_client,
            state = EXCLUDED.state,
            cargo = EXCLUDED.cargo,
            seals = EXCLUDED.seals,
            accept_date = EXCLUDED.accept_date,
            accept_time = EXCLUDED.accept_time,
            in_id = EXCLUDED.in_id,
            in_transport = EXCLUDED.in_transport,
            in_number = EXCLUDED.in_number,
            in_driver = EXCLUDED.in_driver,
            status = EXCLUDED.status,
            updated_at = NOW();
    """)
    
    batch_size = 500
    for i in range(0, len(rows), batch_size):
        batch = rows[i:i + batch_size]
        await session.execute(stmt, batch)
        await session.commit() # –ö–æ–º–º–∏—Ç–∏–º –ø–∞—á–∫–∞–º–∏
    
    logger.info(f"üíæ [DB] Upsert –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {len(rows)} –∑–∞–ø–∏—Å–µ–π (Arrival).")

async def _bulk_update_dispatch(session: AsyncSession, rows: List[dict]):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –º–∞—Å—Å–æ–≤—ã–π UPDATE –¥–ª—è –æ—Ç–≥—Ä—É–∑–∫–∏."""
    if not rows: return

    stmt = text("""
        UPDATE terminal_containers
        SET 
            status = :status,
            dispatch_date = :dispatch_date,
            dispatch_time = :dispatch_time,
            out_id = :out_id,
            out_transport = :out_transport,
            out_number = :out_number,
            out_driver = :out_driver,
            updated_at = :updated_at
        WHERE container_number = :container_number
    """)
    
    batch_size = 500
    for i in range(0, len(rows), batch_size):
        batch = rows[i:i + batch_size]
        await session.execute(stmt, batch)
        await session.commit()
        
    logger.info(f"üöö [DB] Update –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è {len(rows)} –∑–∞–ø–∏—Å–µ–π (Dispatch).")


# =========================================================================
# 3. –õ–û–ì–ò–ö–ê –ê–î–ú–ò–ù–°–ö–û–ì–û –ò–ú–ü–û–†–¢–ê (–§–ê–ô–õ–´ –ü–û–ï–ó–î–û–í) - –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–û
# =========================================================================

async def _collect_containers_from_excel(file_path: str) -> Dict[str, str]:
    """
    –ß–∏—Ç–∞–µ—Ç Excel —Ñ–∞–π–ª –ø–æ–µ–∑–¥–∞ (KXX-YYY) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø—É {–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä: –ö–ª–∏–µ–Ω—Ç}.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∞–¥–º–∏–Ω–∫–µ –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –ø–æ–µ–∑–¥–∞.
    """
    xl = pd.ExcelFile(file_path)
    container_client_map: Dict[str, str] = {}

    for sheet in xl.sheet_names:
        try:
            df = pd.read_excel(xl, sheet_name=sheet)
            # –û—á–∏—Å—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            df.columns = [str(c).strip() for c in df.columns]

            # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            col_container = find_container_column(df)
            
            # –ö–æ–ª–æ–Ω–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∏–Ω–¥–µ–∫—Å 11 - —Å—Ç–æ–ª–±–µ—Ü L)
            col_client = None
            if len(df.columns) > CLIENT_COLUMN_INDEX:
                col_client = df.columns[CLIENT_COLUMN_INDEX]

            if not col_container:
                logger.warning(f"[Train Import] –ù–∞ –ª–∏—Å—Ç–µ '{sheet}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤.")
                continue

            for _, row in df.iterrows():
                cn = normalize_container(row.get(col_container))
                
                cl_val = None
                if col_client:
                    cl_val = clean_string_value(row.get(col_client))
                
                if cn:
                    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å—Ç–∞–≤–∏–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç
                    container_client_map[cn] = cl_val if cl_val else ""
                    
        except Exception as e:
            logger.error(f"[Train Import] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ '{sheet}': {e}")

    return container_client_map

async def import_train_from_excel(src_file_path: str) -> Tuple[int, int, str]:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–¥–º–∏–Ω–∫–∏. –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∫ –ø–æ–µ–∑–¥—É –∏ –∫–ª–∏–µ–Ω—Ç—É.
    """
    train_code = extract_train_code_from_filename(src_file_path)
    if not train_code:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–¥ –ø–æ–µ–∑–¥–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {os.path.basename(src_file_path)}")

    container_map = await _collect_containers_from_excel(src_file_path)
    total_found = len(container_map)

    if total_found == 0:
        logger.warning(f"[Train Import] –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ {src_file_path}")
        return 0, 0, train_code

    updated_count = 0
    
    async with SessionLocal() as session:
        async with session.begin():
            for cn, client_name in container_map.items():
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª–µ train –∏ client —É —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
                stmt = update(TerminalContainer).where(
                    TerminalContainer.container_number == cn
                ).values(
                    train=train_code,
                    client=client_name
                )
                res = await session.execute(stmt)
                updated_count += res.rowcount
    
    logger.info(f"‚úÖ [Train Import] –ü–æ–µ–∑–¥ {train_code}: –ü—Ä–∏–≤—è–∑–∞–Ω–æ {updated_count} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤.")
    return updated_count, total_found, train_code