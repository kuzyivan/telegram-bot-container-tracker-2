# services/dislocation_importer.py

import pandas as pd
import asyncio
import re
import os
from typing import Optional, Dict
from sqlalchemy.future import select
from sqlalchemy import update, delete
from datetime import datetime

# --- –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ ---
from db import async_sessionmaker, SessionLocal # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º SessionLocal
from models import Tracking, TrainEventLog
from logger import get_logger 
from telegram import Bot
from services.imap_service import ImapService # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ö–õ–ê–°–°
from services import notification_service # –î–ª—è –≤—ã–∑–æ–≤–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

logger = get_logger(__name__) 

# --- –û–ü–†–ï–î–ï–õ–Ø–ï–ú –ü–ê–ü–ö–£ –î–õ–Ø –ó–ê–ì–†–£–ó–û–ö ---
DOWNLOAD_DIR = "downloads"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)
# ---

# =========================================================================
# === 1. –ö–ê–†–¢–ê –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø –î–õ–Ø –ù–û–í–û–ì–û –§–û–†–ú–ê–¢–ê ===
# =========================================================================

COLUMN_MAPPING_RZD_NEW = {
    '–ù–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞': 'container_number',
    '–ù–æ–º–µ—Ä –Ω–∞–∫–ª–∞–¥–Ω–æ–π': 'waybill',
    '–¢–∏–ø –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞': 'container_type',
    '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Ä–µ–π—Å–∞': 'trip_start_datetime',
    '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è': 'from_state',
    '–°—Ç–∞–Ω—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è': 'from_station',
    '–î–æ—Ä–æ–≥–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è': 'from_road',
    '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–µ–π—Å–∞': 'trip_end_datetime',
    '–°—Ç—Ä–∞–Ω–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è': 'to_country',
    '–î–æ—Ä–æ–≥–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è': 'to_road',
    '–°—Ç–∞–Ω—Ü–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è': 'to_station',
    '–ì—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å (–¢–ì–ù–õ)': 'sender_tgnl',
    '–ì—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å': 'sender_name_short',
    '–ì—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å (–û–ö–ü–û)': 'sender_okpo',
    '–ì—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å (–Ω–∞–∏–º)': 'sender_name',
    '–ì—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å (–¢–ì–ù–õ)': 'receiver_tgnl',
    '–ì—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å': 'receiver_name_short',
    '–ì—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å (–û–ö–ü–û)': 'receiver_okpo',
    '–ì—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å (–Ω–∞–∏–º)': 'receiver_name',
    '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –≥—Ä—É–∑–∞': 'cargo_name',
    '–ö–æ–¥ –≥—Ä—É–∑–∞ –ì–ù–ì': 'cargo_gng_code',
    '–í–µ—Å –≥—Ä—É–∑–∞ (–∫–≥)': 'cargo_weight_kg',
    '–°—Ç–∞–Ω—Ü–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏': 'current_station',
    '–û–ø–µ—Ä–∞—Ü–∏—è': 'operation',
    '–î–æ—Ä–æ–≥–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏': 'operation_road',
    '–ú–Ω–µ–º–æ–∫–æ–¥ –æ–ø–µ—Ä–∞—Ü–∏–∏': 'operation_mnemonic',
    '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–ø–µ—Ä–∞—Ü–∏–∏': 'operation_date',
    '–°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞': 'container_state',
    '–ò–Ω–¥–µ–∫—Å –ø–æ–µ–∑–¥–∞ —Å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏ —Å—Ç–∞–Ω—Ü–∏–π': 'train_index_full',
    '–ù–æ–º–µ—Ä –ø–æ–µ–∑–¥–∞': 'train_number',
    '–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞': 'wagon_number',
    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–ª–æ–º–±': 'seals_count',
    '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ –ø—Ä–∏–µ–º–∞': 'accept_state',
    '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ —Å–¥–∞—á–∏': 'surrender_state',
    '–î–æ—Ä–æ–≥–∞ –ø—Ä–∏–µ–º–∞': 'accept_road',
    '–î–æ—Ä–æ–≥–∞ —Å–¥–∞—á–∏': 'surrender_road',
    '–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π —Å—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏': 'delivery_deadline',
    '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ–±—â–µ–µ': 'total_distance',
    '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–π–¥–µ–Ω–Ω–æ–µ': 'distance_traveled',
    '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è': 'km_left',
    '–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è –ø–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–ø–µ—Ä–∞—Ü–∏–µ–π (—Å—É—Ç–∫–∏:—á–∞—Å—ã:–º–∏–Ω—É—Ç—ã)': 'last_op_idle_time_str',
    '–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è –ø–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–ø–µ—Ä–∞—Ü–∏–µ–π (—Å—É—Ç–∫–∏)': 'last_op_idle_days',
    '–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ—Ç–ø—Ä–∞–≤–∫–∏': 'dispatch_id',
    '–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–∫–ª–∞–¥–Ω–æ–π': 'waybill_id',
    '–ü—Ä–∏–∑–Ω–∞–∫ –≥—Ä—É–∂. —Ä–µ–π—Å–∞': 'is_loaded_trip',
}

# =========================================================================
# === 2. –•–ï–õ–ü–ï–†–´ ===
# =========================================================================

def _fill_empty_rows_with_previous(df: pd.DataFrame, column_name: str) -> pd.DataFrame:
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏."""
    df[column_name] = df[column_name].ffill()
    return df

# =========================================================================
# === 3. "–£–ú–ù–´–ô" –ß–ò–¢–ê–¢–ï–õ–¨ –§–ê–ô–õ–û–í ===
# =========================================================================

def _read_excel_data(filepath: str) -> Optional[pd.DataFrame]:
    """
    –°—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ .xlsx —Ñ–∞–π–ª–∞ –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏ –æ—Ç –†–ñ–î, 
    –ø—Ä–æ–ø—É—Å–∫–∞—è 3 —Å—Ç—Ä–æ–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑—É—è 4-—é –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å –£–ñ–ï –ü–ï–†–ï–ò–ú–ï–ù–û–í–ê–ù–ù–´–ú–ò —Å—Ç–æ–ª–±—Ü–∞–º–∏ (–∫–ª—é—á–∞–º–∏ –º–æ–¥–µ–ª–∏).
    """
    logger.info(f"–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏: {filepath}")
    
    try:
        df = pd.read_excel(filepath, skiprows=3, header=0, engine='openpyxl')
        
        if '–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ—Ç–ø—Ä–∞–≤–∫–∏' in df.columns or '–¢–∏–ø –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞' in df.columns:
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ù–û–í–´–ô —Ñ–æ—Ä–º–∞—Ç –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏ (–†–ñ–î, 45 —Å—Ç–æ–ª–±—Ü–æ–≤).")
            
            valid_columns = [col for col in df.columns if col in COLUMN_MAPPING_RZD_NEW]
            if not valid_columns:
                logger.error("–ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ COLUMN_MAPPING_RZD_NEW.")
                return None
            df = df[valid_columns]
            
            df.rename(columns=COLUMN_MAPPING_RZD_NEW, inplace=True)
            
            if 'container_number' in df.columns:
                df = _fill_empty_rows_with_previous(df, 'container_number')
            else:
                logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: '–ù–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ù–û–í–û–ú —Ñ–∞–π–ª–µ.")
                return None

            df = df.where(pd.notna(df), None)
            return df
            
        else:
            logger.error(f"–§–∞–π–ª {filepath} –Ω–µ –ø–æ—Ö–æ–∂ –Ω–∞ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç (–Ω–µ—Ç –º–∞—Ä–∫–µ—Ä-—Å—Ç–æ–ª–±—Ü–æ–≤).")
            return None
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞ {filepath}: {e}", exc_info=True)
        return None


# =========================================================================
# === 4. –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö –î–õ–Ø –ë–î ===
# =========================================================================

async def process_dislocation_file(filepath: str):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏, –æ–±–Ω–æ–≤–ª—è–µ—Ç/–≤—Å—Ç–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
    –∏ –≥–æ—Ç–æ–≤–∏—Ç —Å–æ–±—ã—Ç–∏—è –¥–ª—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    
    df = await asyncio.to_thread(_read_excel_data, filepath)
    if df is None:
        logger.warning(f"–§–∞–π–ª {filepath} –Ω–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, dataframe –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω —Ñ–æ—Ä–º–∞—Ç.")
        return 0

    data_rows = df.to_dict('records') 
    
    updated_count = 0
    inserted_count = 0
    events_to_log = [] 

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–±—Ä–∏–∫—É —Å–µ—Å—Å–∏–π –∏–∑ db.py
    session = SessionLocal() # <--- –ò–°–ü–†–ê–í–õ–ï–ù–û (–∏—Å–ø–æ–ª—å–∑—É–µ–º SessionLocal)
    try:
        
        container_numbers_from_file = [
            row['container_number'] for row in data_rows if row.get('container_number')
        ]
        if not container_numbers_from_file:
            logger.warning(f"–í —Ñ–∞–π–ª–µ {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.")
        else:
            existing_trackings = (await session.execute(
                select(Tracking).where(Tracking.container_number.in_(set(container_numbers_from_file)))
            )).scalars().all()
            tracking_map = {t.container_number: t for t in existing_trackings}

            for row_data in data_rows:
                
                container_number = row_data.get('container_number')
                if not container_number:
                    continue

                # --- –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ ---
                if 'is_loaded_trip' in row_data and row_data['is_loaded_trip'] is not None:
                    row_data['is_loaded_trip'] = bool(row_data['is_loaded_trip'])
                
                for date_col in ['operation_date', 'trip_start_datetime', 'trip_end_datetime', 'delivery_deadline']:
                    if date_col in row_data and row_data[date_col] is not None:
                        if pd.isna(row_data[date_col]):
                            row_data[date_col] = None
                        else:
                            try:
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ python datetime
                                py_dt = pd.to_datetime(row_data[date_col]).to_pydatetime()
                                # –£–±–∏—Ä–∞–µ–º tzinfo, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å, —Ç.–∫. –≤ –ë–î –∫–æ–ª–æ–Ω–∫–∞ –±–µ–∑ timezone
                                if py_dt.tzinfo:
                                    py_dt = py_dt.replace(tzinfo=None)
                                row_data[date_col] = py_dt
                            except:
                                row_data[date_col] = None

                for key in ['cargo_weight_kg', 'total_distance', 'distance_traveled', 'km_left']:
                    if key in row_data and row_data[key] is not None:
                        try:
                            row_data[key] = int(row_data[key])
                        except (ValueError, TypeError):
                            row_data[key] = None 
                # --- –ö–æ–Ω–µ—Ü –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤ ---

                existing_entry = tracking_map.get(container_number)
                new_operation_date = row_data.get('operation_date') 
                
                if existing_entry:
                    # --- –õ–û–ì–ò–ö–ê –û–ë–ù–û–í–õ–ï–ù–ò–Ø ---
                    current_date = existing_entry.operation_date 
                    if new_operation_date and (current_date is None or new_operation_date > current_date):
                        for key, value in row_data.items():
                            setattr(existing_entry, str(key), value)
                        
                        events_to_log.append(TrainEventLog(
                            container_number=container_number,
                            train_number=row_data.get('train_number', 'N/A'),
                            event_description=row_data.get('operation', '–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ'),
                            station=row_data.get('current_station', 'N/A'),
                            event_time=new_operation_date
                        ))
                        updated_count += 1
                else:
                    # --- –õ–û–ì–ò–ö–ê –°–û–ó–î–ê–ù–ò–Ø ---
                    new_entry_data = {str(k): v for k, v in row_data.items()}
                    new_entry = Tracking(**new_entry_data) 
                    session.add(new_entry)
                    tracking_map[container_number] = new_entry 
                    
                    events_to_log.append(TrainEventLog(
                        container_number=container_number,
                        train_number=row_data.get('train_number', 'N/A'),
                        event_description="–ó–∞–ø–∏—Å—å —Å–æ–∑–¥–∞–Ω–∞",
                        station=row_data.get('current_station', 'N/A'),
                        event_time=new_operation_date if new_operation_date else datetime.now()
                    ))
                    inserted_count += 1
                    
        if events_to_log:
            session.add_all(events_to_log)
        
        await session.commit()
        logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: {inserted_count} –Ω–æ–≤—ã—Ö, {updated_count} –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö.")
        
    except Exception as e:
        await session.rollback()
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: {e}", exc_info=True)
        return 0
    finally:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å–µ—Å—Å–∏—è –∑–∞–∫—Ä—ã—Ç–∞
        await session.close()

    logger.info(f"[Dislocation Import] –û–±—Ä–∞–±–æ—Ç–∫–∞ {filepath} –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    return inserted_count + updated_count


# =========================================================================
# === 5. –§–£–ù–ö–¶–ò–Ø, –í–´–ó–´–í–ê–ï–ú–ê–Ø –ü–õ–ê–ù–ò–†–û–í–©–ò–ö–û–ú (–ò–°–ü–†–ê–í–õ–ï–ù–ê) ===
# =========================================================================

# –§–∏–ª—å—Ç—Ä—ã –∏–∑ –≤–∞—à–µ–≥–æ repomix
SUBJECT_FILTER_DISLOCATION = r'^–û—Ç—á—ë—Ç —Å–ª–µ–∂–µ–Ω–∏—è TrackerBot ‚Ññ'
SENDER_FILTER_DISLOCATION = 'cargolk@gvc.rzd.ru'
# --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–ø—É—Å–∫–∞–µ–º .xls –∏ .xlsx ---
FILENAME_PATTERN_DISLOCATION = r'\.(xlsx|xls)$' 

async def check_and_process_dislocation(bot_instance: Bot):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—á—Ç—É, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã –∏ —Ä–∞—Å—Å—ã–ª–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è."""
    
    logger.info("Scheduler: –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏...")
    try:
        # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –í–´–ó–û–í–ê: ---
        # 1. –°–æ–∑–¥–∞–µ–º –≠–ö–ó–ï–ú–ü–õ–Ø–† –∫–ª–∞—Å—Å–∞ (–±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤)
        #    –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä ImapService —Å–∞–º —á–∏—Ç–∞–µ—Ç .env
        imap = ImapService()
        
        # 2. –í—ã–∑—ã–≤–∞–µ–º –ú–ï–¢–û–î –Ω–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–µ
        filepath = await asyncio.to_thread(
            imap.download_latest_attachment,
            subject_filter=SUBJECT_FILTER_DISLOCATION,
            sender_filter=SENDER_FILTER_DISLOCATION,
            filename_pattern=FILENAME_PATTERN_DISLOCATION
        )
        # --- –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ---

        if filepath:
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏: {filepath}")
            try:
                # 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
                processed_count = await process_dislocation_file(filepath)
                
                # 2. –†–∞—Å—Å—ã–ª–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ)
                if processed_count > 0:
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∑–∞–ø–∏—Å–µ–π. –ó–∞–ø—É—Å–∫ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π —Ä–∞—Å—Å—ã–ª–∫–∏...")
                    service = notification_service.NotificationService(bot_instance)
                    await service.send_aggregated_train_event_notifications()
                else:
                    logger.info("–§–∞–π–ª –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏ –Ω–µ –ø—Ä–∏–≤–µ–ª –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º, —Ä–∞—Å—Å—ã–ª–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏ {filepath}: {e}", exc_info=True)
            finally:
                if os.path.exists(filepath):
                    os.remove(filepath)
                    logger.info(f"[Dislocation Import] –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {os.path.basename(filepath)} —É–¥–∞–ª–µ–Ω.")
        else:
            logger.info("üì¨ [Dislocation] –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–∏—Å–ª–æ–∫–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

    except AttributeError as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê: {e}")
        logger.error("     –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ 'services/imap_service.py' —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å 'ImapService'.")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ check_and_process_dislocation: {e}", exc_info=True)
        # –ù–µ "raise e", —á—Ç–æ–±—ã –Ω–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Ç–µ—Å—Ç
        