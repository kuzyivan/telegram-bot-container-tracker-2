# services/container_importer.py
from __future__ import annotations

import os
import re
from typing import List, Tuple, Iterable

import pandas as pd
from sqlalchemy import text

from db import SessionLocal
from logger import get_logger

logger = get_logger(__name__)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –£—Ç–∏–ª–∏—Ç—ã (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def extract_train_code_from_filename(filename: str) -> str | None:
    name = os.path.basename(filename)
    m = re.search(r"–ö\d{2}-\d{3}", name, flags=re.IGNORECASE)
    if not m:
        return None
    code = m.group(0)
    code = "–ö" + code[1:]
    return code


def normalize_container(value) -> str | None:
    if value is None:
        return None
    s = str(value).strip().upper()
    if not s or s == "NAN":
        return None
    s = re.sub(r"\s+", "", s)
    return s


def find_container_column(df: pd.DataFrame) -> str | None:
    lowered = {str(c).strip(): str(c).strip().lower() for c in df.columns}
    keys = [
        "–Ω–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", "container", "container no",
        "container number", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Ññ", "‚Ññ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞",
    ]
    for orig, low in lowered.items():
        if any(k in low for k in keys):
            return orig
    return None


async def _collect_containers_from_excel(file_path: str) -> List[str]:
    if not os.path.exists(file_path):
        raise FileNotFoundError(file_path)

    xls = pd.ExcelFile(file_path)
    containers: List[str] = []

    for sheet in xls.sheet_names:
        try:
            df = pd.read_excel(file_path, sheet_name=sheet)
        except Exception:
            continue
        col = find_container_column(df)
        if not col:
            continue

        vals = [normalize_container(v) for v in df[col].dropna().tolist()]
        vals = [v for v in vals if v]
        containers.extend(vals)

    seen = set()
    uniq: List[str] = []
    for c in containers:
        if c not in seen:
            seen.add(c)
            uniq.append(c)
    return uniq


def _chunks(seq: Iterable[str], size: int) -> Iterable[List[str]]:
    buf: List[str] = []
    for x in seq:
        buf.append(x)
        if len(buf) >= size:
            yield buf
            buf = []
    if buf:
        yield buf


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ò–º–ø–æ—Ä—Ç Executive summary ‚Üí terminal_containers (–ò–°–ü–†–ê–í–õ–ï–ù–û)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def import_loaded_and_dispatch_from_excel(file_path: str) -> Tuple[int, int]:
    """
    –ò–º–ø–æ—Ä—Ç –∏–∑ –æ—Ç—á—ë—Ç–∞ Executive summary.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (added_total, processed_sheets)
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(file_path)

    xls = pd.ExcelFile(file_path)
    sheet_names = xls.sheet_names
    target_sheets = [
        s for s in sheet_names
        if str(s).strip().lower().startswith(("dispatch", "loaded"))
    ]

    added_total = 0
    processed = 0

    async with SessionLocal() as session:
        for sheet in target_sheets:
            try:
                df = pd.read_excel(file_path, sheet_name=sheet)
                col = find_container_column(df)
                if not col:
                    logger.warning(f"[Executive summary] –ù–∞ –ª–∏—Å—Ç–µ '{sheet}' –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏.")
                    continue

                values = [normalize_container(v) for v in df[col].dropna().tolist()]
                containers = [v for v in values if v]

                if not containers:
                    processed += 1
                    continue

                for cn in containers:
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º 'RETURNING id'
                    # –≠—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± —É–∑–Ω–∞—Ç—å, –±—ã–ª–∞ –ª–∏ —Ä–µ–∞–ª—å–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å.
                    # –ó–∞–ø—Ä–æ—Å —Ç–µ–ø–µ—Ä—å –ø—Ä–æ—Å–∏—Ç –ë–î –≤–µ—Ä–Ω—É—Ç—å 'id' –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏. –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –±—ã–ª–∞
                    # –≤—Å—Ç–∞–≤–ª–µ–Ω–∞ (–∏–∑-–∑–∞ ON CONFLICT), —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º.
                    res = await session.execute(
                        text("""
                            INSERT INTO terminal_containers (container_number)
                            VALUES (:cn)
                            ON CONFLICT (container_number) DO NOTHING
                            RETURNING id
                        """),
                        {"cn": cn},
                    )
                    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç .scalar_one_or_none() –Ω–µ None, –∑–Ω–∞—á–∏—Ç, –≤—Å—Ç–∞–≤–∫–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞.
                    if res.scalar_one_or_none() is not None:
                        added_total += 1

                await session.commit()
                processed += 1

            except Exception as e:
                logger.exception(f"[Executive summary] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Å—Ç–∞ '{sheet}': {e}")

    logger.info(f"üì• –ò–º–ø–æ—Ä—Ç Executive summary: –ª–∏—Å—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ={processed}, –¥–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤={added_total}")
    return added_total, processed


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ò–º–ø–æ—Ä—Ç ¬´–ø–æ–µ–∑–¥–Ω—ã—Ö¬ª —Ñ–∞–π–ª–æ–≤ ‚Üí terminal_containers.train (–ò–°–ü–†–ê–í–õ–ï–ù–û)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def import_train_excel(src_file_path: str) -> Tuple[int, int, str]:
    """
    –ò–º–ø–æ—Ä—Ç —Ä—É—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–æ–µ–∑–¥–æ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (updated_count, containers_total, train_code).
    """
    if not os.path.exists(src_file_path):
        raise FileNotFoundError(src_file_path)

    train_code = extract_train_code_from_filename(src_file_path)
    if not train_code:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–¥ –ø–æ–µ–∑–¥–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è —à–∞–±–ª–æ–Ω '–ö–î–î-–ù–ù–ù'.")

    containers = await _collect_containers_from_excel(src_file_path)
    total = len(containers)
    if total == 0:
        logger.info(f"[Train] –í —Ñ–∞–π–ª–µ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {os.path.basename(src_file_path)}")
        return 0, 0, train_code

    updated_sum = 0
    async with SessionLocal() as session:
        for chunk in _chunks(containers, 500):
            res = await session.execute(
                text("""
                    UPDATE terminal_containers
                       SET train = :train
                     WHERE container_number = ANY(:cn_list)
                """),
                {"train": train_code, "cn_list": chunk},
            )
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º '# type: ignore'
            # –î–ª—è –∫–æ–º–∞–Ω–¥—ã UPDATE –∞—Ç—Ä–∏–±—É—Ç .rowcount —è–≤–ª—è–µ—Ç—Å—è –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
            # —É–∑–Ω–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫. Pylance –æ—à–∏–±–∞–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ –æ–±—â–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è
            # Result –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –Ω–∞–ª–∏—á–∏–µ. –ú—ã "—É—Å–ø–æ–∫–∞–∏–≤–∞–µ–º" Pylance, –≥–æ–≤–æ—Ä—è,
            # —á—Ç–æ –º—ã —É–≤–µ—Ä–µ–Ω—ã –≤ –Ω–∞–ª–∏—á–∏–∏ —ç—Ç–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞ –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
            updated_sum += res.rowcount  # type: ignore

        await session.commit()

    logger.info(f"üöÜ –ü—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω –ø–æ–µ–∑–¥ {train_code}: –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_sum} –∏–∑ {total} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ "
                f"({os.path.basename(src_file_path)})")
    return updated_sum, total, train_code