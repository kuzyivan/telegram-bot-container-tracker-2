# tariff_migrator.py
import asyncio
import os
import re
import pandas as pd
import sys
from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy import String, Integer, ARRAY, Index, UniqueConstraint
from sqlalchemy.exc import IntegrityError
import logging

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ .env ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ zdtarif_bot/data
current_file_path = os.path.abspath(__file__)
project_root_dir = os.path.dirname(current_file_path)
sys.path.insert(0, project_root_dir)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–æ—Å–æ–±–µ–Ω–Ω–æ TARIFF_DATABASE_URL)
load_dotenv()
TARIFF_DB_URL = os.getenv("TARIFF_DATABASE_URL")

# --- 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ORM –ú–æ–¥–µ–ª–µ–π –¥–ª—è –Ω–æ–≤–æ–π –ë–î ---

class Base(DeclarativeBase):
    pass

class TariffStation(Base):
    '''
    –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ 2-–†–ü.csv.
    '''
    __tablename__ = 'tariff_stations'
    id: Mapped[int] = mapped_column(primary_key=True)
    
    # '–ß–µ–º—Å–∫–æ–π'
    name: Mapped[str] = mapped_column(String, index=True, unique=True) 
    
    # '850308'
    code: Mapped[str] = mapped_column(String(6), index=True) 
    
    # '–ó–ê–ü–ê–î–ù–û-–°–ò–ë–ò–†–°–ö–ê–Ø (83)'
    railway: Mapped[str | None] = mapped_column(String)
    
    # –¢—Ä–∞–Ω–∑–∏—Ç–Ω—ã–µ –ø—É–Ω–∫—Ç—ã (–¢–ü)
    # –ú—ã –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏ ["–ö–û–î:–ò–ú–Ø:–î–ò–°–¢–ê–ù–¶–ò–Ø", ...]
    transit_points: Mapped[list[str] | None] = mapped_column(ARRAY(String)) 

    __table_args__ = (
        Index('ix_tariff_stations_name_code', 'name', 'code'),
    )

class TariffMatrix(Base):
    '''
    –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ 3-1 –†–æ—Å.csv –∏ 3-2 –†–æ—Å.csv.
    '''
    __tablename__ = 'tariff_matrix'
    id: Mapped[int] = mapped_column(primary_key=True)
    
    # '–ë–µ–∫–∞—Å–æ–≤–æ I'
    station_a: Mapped[str] = mapped_column(String, index=True)
    
    # '–ò–Ω—Å–∫–∞—è'
    station_b: Mapped[str] = mapped_column(String, index=True)
    
    # 1532
    distance: Mapped[int] = mapped_column(Integer)

    __table_args__ = (
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç—ã
        UniqueConstraint('station_a', 'station_b', name='uq_station_pair'),
    )

# --- 3. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ ---

def parse_transit_points_for_db(tp_string: str) -> list[str]:
    '''
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ç—Ä–∞–Ω–∑–∏—Ç–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ –∏–∑ 2-–†–ü.csv –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.
    '''
    if not isinstance(tp_string, str) or not tp_string:
        return []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –∏–∑ zdtarif_bot/core/data_parser.py
    pattern = re.compile(r'(\d{6})\s(.*?)\s-\s(\d+)–∫–º')
    matches = pattern.findall(tp_string)
    
    transit_points_str = []
    for match in matches:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø—Ä–æ—Å—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ "–ö–û–î:–ò–ú–Ø:–î–ò–°–¢–ê–ù–¶–ò–Ø"
        transit_points_str.append(f"{match[0]}:{match[1].strip()}:{int(match[2])}")
        
    return transit_points_str

def load_kniga_2_rp(filepath: str) -> pd.DataFrame | None:
    '''
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç 2-–†–ü.csv –∏–∑ zdtarif_bot/data
    '''
    try:
        df = pd.read_csv(
            filepath,
            # --- üêû –í–û–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï üêû ---
            skiprows=6, # –ë—ã–ª–æ 5, –º–µ–Ω—è–µ–º –Ω–∞ 6, —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞
            # --- üèÅ –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø üèÅ ---
            names=[
                'num', 'station_name', 'operations', 'railway', 
                'transit_points_raw', 'station_code'
            ],
            encoding='cp1251',
            dtype={'station_code': str} # –ß–∏—Ç–∞–µ–º –∫–æ–¥ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
        )
        df['station_name'] = df['station_name'].str.strip()
        df['station_code'] = df['station_code'].str.strip()
        df['railway'] = df['railway'].str.strip()
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∏–º–µ–Ω–∏ –∏–ª–∏ –∫–æ–¥–∞
        df.dropna(subset=['station_name', 'station_code'], inplace=True)
        
        log.info(f"‚úÖ –§–∞–π–ª {os.path.basename(filepath)} –∑–∞–≥—Ä—É–∂–µ–Ω, {len(df)} —Å—Ç–∞–Ω—Ü–∏–π.")
        return df
    except FileNotFoundError:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª '{filepath}'.")
        return None
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {filepath}: {e}", exc_info=True)
        return None

def load_kniga_3_matrix(filepath: str) -> pd.DataFrame | None:
    '''
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É (3-1 –∏–ª–∏ 3-2) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–µ –≤ "–¥–ª–∏–Ω–Ω—ã–π" —Ñ–æ—Ä–º–∞—Ç.
    '''
    try:
        # --- üêû –í–û–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï üêû ---
        df = pd.read_csv(filepath, skiprows=6, encoding='cp1251') # –ë—ã–ª–æ 5, –º–µ–Ω—è–µ–º –Ω–∞ 6
        # --- üèÅ –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø üèÅ ---
        
        # –ü–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ (–∏–Ω–¥–µ–∫—Å) - —ç—Ç–æ station_a
        df.iloc[:, 1] = df.iloc[:, 1].astype(str).str.strip()
        df = df.set_index(df.columns[1])
        df = df.drop(columns=[df.columns[0]]) # –£–¥–∞–ª—è–µ–º '‚Ññ –ø/–ø'
        
        # –ö–æ–ª–æ–Ω–∫–∏ - —ç—Ç–æ station_b
        df.columns = df.columns.str.strip()

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –≤ "–¥–ª–∏–Ω–Ω—ã–π" —Ñ–æ—Ä–º–∞—Ç: (station_a, station_b, distance)
        df_long = df.stack(dropna=True).reset_index()
        df_long.columns = ['station_a', 'station_b', 'distance']
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ int
        df_long = df_long[pd.to_numeric(df_long['distance'], errors='coerce').notna()]
        df_long['distance'] = df_long['distance'].astype(int)
        
        # –£–¥–∞–ª—è–µ–º –º–∞—Ä—à—Ä—É—Ç—ã —Å 0 –∫–º
        df_long = df_long[df_long['distance'] > 0]
        
        log.info(f"‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ {os.path.basename(filepath)} –∑–∞–≥—Ä—É–∂–µ–Ω–∞, {len(df_long)} –º–∞—Ä—à—Ä—É—Ç–æ–≤.")
        return df_long
    except FileNotFoundError:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª '{filepath}'.")
        return None
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ç—Ä–∏—Ü—ã {filepath}: {e}", exc_info=True)
        return None

# --- 4. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏ ---

async def main_migrate():
    '''
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è, —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ.
    '''
    if not TARIFF_DB_URL:
        log.error("‚ùå TARIFF_DATABASE_URL –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ .env —Ñ–∞–π–ª–µ. –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        return
        
    log.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –Ω–æ–≤–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç–∞—Ä–∏—Ñ–æ–≤: {TARIFF_DB_URL.split('@')[-1]}")
    
    # 1. –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ –∏ —Ç–∞–±–ª–∏—Ü—ã
    engine = create_async_engine(TARIFF_DB_URL)
    async with engine.begin() as conn:
        log.info("–û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü (–µ—Å–ª–∏ –µ—Å—Ç—å)...")
        await conn.run_sync(Base.metadata.drop_all)
        log.info("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü (tariff_stations, tariff_matrix)...")
        await conn.run_sync(Base.metadata.create_all)
    
    Session = async_sessionmaker(engine, expire_on_commit=False)
    
    # 2. –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π (2-–†–ü.csv)
    log.info("--- 1/3: –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é –°—Ç–∞–Ω—Ü–∏–π (2-–†–ü.csv) ---")
    data_dir_path = os.path.join(project_root_dir, 'zdtarif_bot', 'data')
    stations_df = load_kniga_2_rp(os.path.join(data_dir_path, '2-–†–ü.csv'))
    
    if stations_df is not None:
        async with Session() as session:
            async with session.begin():
                stations_to_add = []
                for _, row in stations_df.iterrows():
                    stations_to_add.append(
                        TariffStation(
                            name=row['station_name'],
                            code=row['station_code'],
                            railway=row['railway'],
                            transit_points=parse_transit_points_for_db(row['transit_points_raw'])
                        )
                    )
                log.info(f"–î–æ–±–∞–≤–ª—è—é {len(stations_to_add)} —Å—Ç–∞–Ω—Ü–∏–π –≤ –±–∞–∑—É...")
                session.add_all(stations_to_add)
            await session.commit()
        log.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    else:
        log.error("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π –ø—Ä–æ–≤–∞–ª–µ–Ω–∞, —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")
        return

    # 3. –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 1 (3-1 –†–æ—Å.csv)
    log.info("--- 2/3: –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é –ú–∞—Ç—Ä–∏—Ü—ã 1 (3-1 –†–æ—Å.csv) ---")
    matrix_1_df = load_kniga_3_matrix(os.path.join(data_dir_path, '3-1 –†–æ—Å.csv'))
    
    if matrix_1_df is not None:
        async with Session() as session:
            async with session.begin():
                log.info(f"–î–æ–±–∞–≤–ª—è—é {len(matrix_1_df)} –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ 3-1 –†–æ—Å...")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º bulk_insert_mappings –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤—Å—Ç–∞–≤–∫–∏
                await session.run_sync(
                    lambda s: s.bulk_insert_mappings(
                        TariffMatrix, 
                        matrix_1_df.to_dict(orient='records')
                    )
                )
            await session.commit()
        log.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    else:
        log.error("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 1 –ø—Ä–æ–≤–∞–ª–µ–Ω–∞, —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    # 4. –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 2 (3-2 –†–æ—Å.csv)
    log.info("--- 3/3: –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é –ú–∞—Ç—Ä–∏—Ü—ã 2 (3-2 –†–æ—Å.csv) ---")
    matrix_2_df = load_kniga_3_matrix(os.path.join(data_dir_path, '3-2 –†–æ—Å.csv'))
    
    if matrix_2_df is not None:
        async with Session() as session:
            async with session.begin():
                log.info(f"–î–æ–±–∞–≤–ª—è—é {len(matrix_2_df)} –º–∞—Ä—à—Ä—É—Ç–æ–≤ –∏–∑ 3-2 –†–æ—Å...")
                try:
                    await session.run_sync(
                        lambda s: s.bulk_insert_mappings(
                            TariffMatrix, 
                            matrix_2_df.to_dict(orient='records')
                        )
                    )
                except IntegrityError as e:
                    await session.rollback()
                    log.warning(f"–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: {e.orig}")
                    log.warning("–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –±—ã–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –º–∞—Ä—à—Ä—É—Ç–æ–≤. –ü—Ä–æ–¥–æ–ª–∂–∞—é...")
                except Exception as e:
                    log.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
                    await session.rollback()
            await session.commit()
        log.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    else:
        log.error("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –ú–∞—Ç—Ä–∏—Ü—ã 2 –ø—Ä–æ–≤–∞–ª–µ–Ω–∞, —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    log.info("üéâüéâüéâ == –ú–ò–ì–†–ê–¶–ò–Ø –¢–ê–†–ò–§–ù–û–ô –ë–ê–ó–´ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê! ==")
    log.info("–ü–∞–ø–∫—É zdtarif_bot/data –º–æ–∂–Ω–æ —É–¥–∞–ª—è—Ç—å.")
    
    await engine.dispose()


if __name__ == "__main__":
    asyncio.run(main_migrate())