# tariff_migrator.py
import asyncio
import os
import re
import pandas as pd
import sys
import glob # <-- –í–∞–∂–Ω—ã–π –∏–º–ø–æ—Ä—Ç
from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy import String, Integer, ARRAY, Index, UniqueConstraint
from sqlalchemy.exc import IntegrityError
from sqlalchemy.dialects.postgresql import insert as pg_insert
import logging

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ .env ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ zdtarif_bot/data
current_file_path = os.path.abspath(__file__)
project_root_dir = os.path.dirname(current_file_path)
sys.path.insert(0, project_root_dir)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–æ—Å–æ–±–µ–Ω–Ω–æ TARIFF_DATABASE_URL)
load_dotenv()
TARIFF_DB_URL = os.getenv("TARIFF_DATABASE_URL")

# --- 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ORM –ú–æ–¥–µ–ª–µ–π –¥–ª—è –Ω–æ–≤–æ–π –ë–î ---

class Base(DeclarativeBase):
    pass

class TariffStation(Base):
    '''
    –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ 2-–†–ü.csv.
    '''
    __tablename__ = 'tariff_stations'
    id: Mapped[int] = mapped_column(primary_key=True)
    name: Mapped[str] = mapped_column(String, index=True, unique=True) 
    code: Mapped[str] = mapped_column(String(6), index=True) 
    railway: Mapped[str | None] = mapped_column(String)
    transit_points: Mapped[list[str] | None] = mapped_column(ARRAY(String)) 

    __table_args__ = (
        Index('ix_tariff_stations_name_code', 'name', 'code'),
    )

class TariffMatrix(Base):
    '''
    –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ 3-*.csv.
    '''
    __tablename__ = 'tariff_matrix'
    id: Mapped[int] = mapped_column(primary_key=True)
    station_a: Mapped[str] = mapped_column(String, index=True)
    station_b: Mapped[str] = mapped_column(String, index=True)
    distance: Mapped[int] = mapped_column(Integer)

    __table_args__ = (
        UniqueConstraint('station_a', 'station_b', name='uq_station_pair'),
    )

# --- 3. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ ---

def parse_transit_points_for_db(tp_string: str) -> list[str]:
    '''
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ç—Ä–∞–Ω–∑–∏—Ç–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ –∏–∑ 2-–†–ü.csv –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.
    '''
    if not isinstance(tp_string, str) or not tp_string:
        return []
    
    pattern = re.compile(r'(\d{6})\s(.*?)\s-\s(\d+)–∫–º')
    matches = pattern.findall(tp_string)
    
    transit_points_str = []
    for match in matches:
        transit_points_str.append(f"{match[0]}:{match[1].strip()}:{int(match[2])}")
        
    return transit_points_str

def load_kniga_2_rp(filepath: str) -> pd.DataFrame | None:
    '''
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç 2-–†–ü.csv –∏–∑ zdtarif_bot/data
    '''
    try:
        df = pd.read_csv(
            filepath,
            skiprows=6, # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            names=[
                'num', 'station_name', 'operations', 'railway', 
                'transit_points_raw', 'station_code'
            ],
            encoding='cp1251',
            dtype={'station_code': str} 
        )
        df['station_name'] = df['station_name'].str.strip()
        df['station_code'] = df['station_code'].str.strip()
        df['railway'] = df['railway'].str.strip()
        df.dropna(subset=['station_name', 'station_code'], inplace=True)
        df.drop_duplicates(subset=['station_name'], keep='first', inplace=True)
        
        log.info(f"‚úÖ –§–∞–π–ª {os.path.basename(filepath)} –∑–∞–≥—Ä—É–∂–µ–Ω, {len(df)} –£–ù–ò–ö–ê–õ–¨–ù–´–• —Å—Ç–∞–Ω—Ü–∏–π.")
        return df
    except FileNotFoundError:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª '{filepath}'.")
        return None
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {filepath}: {e}", exc_info=True)
        return None

def load_kniga_3_matrix(filepath: str) -> pd.DataFrame | None:
    '''
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É (3-*.csv) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–µ –≤ "–¥–ª–∏–Ω–Ω—ã–π" —Ñ–æ—Ä–º–∞—Ç.
    '''
    try:
        df = pd.read_csv(filepath, skiprows=6, encoding='cp1251') # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        
        df.iloc[:, 1] = df.iloc[:, 1].astype(str).str.strip()
        df = df.set_index(df.columns[1])
        df = df.drop(columns=[df.columns[0]]) # –£–¥–∞–ª—è–µ–º '‚Ññ –ø/–ø'
        
        df.columns = df.columns.str.strip()

        # --- üêû –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï (ValueError: dropna must be unspecified) üêû ---
        df_long = df.stack(future_stack=True).reset_index() 
        # --- üèÅ –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø üèÅ ---
        
        df_long.columns = ['station_a', 'station_b', 'distance']
        
        df_long = df_long[pd.to_numeric(df_long['distance'], errors='coerce').notna()]
        df_long['distance'] = df_long['distance'].astype(int)
        
        df_long = df_long[df_long['distance'] > 0]
        
        df_long.drop_duplicates(subset=['station_a', 'station_b'], keep='first', inplace=True)
        
        log.info(f"‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ {os.path.basename(filepath)} –∑–∞–≥—Ä—É–∂–µ–Ω–∞, {len(df_long)} –£–ù–ò–ö–ê–õ–¨–ù–´–• –º–∞—Ä—à—Ä—É—Ç–æ–≤.")
        return df_long
    except FileNotFoundError:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª '{filepath}'.")
        return None
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ç—Ä–∏—Ü—ã {filepath}: {e}", exc_info=True)
        return None

# --- 4. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏ ---

async def main_migrate():
    '''
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è, —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ.
    '''
    if not TARIFF_DB_URL:
        log.error("‚ùå TARIFF_DATABASE_URL –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ .env —Ñ–∞–π–ª–µ. –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        return
        
    log.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –Ω–æ–≤–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç–∞—Ä–∏—Ñ–æ–≤: {TARIFF_DB_URL.split('@')[-1]}")
    
    # 1. –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ –∏ —Ç–∞–±–ª–∏—Ü—ã
    engine = create_async_engine(TARIFF_DB_URL)
    async with engine.begin() as conn:
        log.info("–û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü (–µ—Å–ª–∏ –µ—Å—Ç—å)...")
        await conn.run_sync(Base.metadata.drop_all)
        log.info("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü (tariff_stations, tariff_matrix)...")
        await conn.run_sync(Base.metadata.create_all)
    
    Session = async_sessionmaker(engine, expire_on_commit=False)
    
    # 2. –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π (2-–†–ü.csv)
    log.info("--- 1/2: –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é –°—Ç–∞–Ω—Ü–∏–π (2-–†–ü.csv) ---")
    data_dir_path = os.path.join(project_root_dir, 'zdtarif_bot', 'data')
    stations_df = load_kniga_2_rp(os.path.join(data_dir_path, '2-–†–ü.csv'))
    
    if stations_df is not None:
        async with Session() as session:
            async with session.begin():
                stations_to_add = []
                for _, row in stations_df.iterrows():
                    stations_to_add.append(
                        TariffStation(
                            name=row['station_name'],
                            code=row['station_code'],
                            railway=row['railway'],
                            transit_points=parse_transit_points_for_db(row['transit_points_raw'])
                        )
                    )
                log.info(f"–î–æ–±–∞–≤–ª—è—é {len(stations_to_add)} —Å—Ç–∞–Ω—Ü–∏–π –≤ –±–∞–∑—É...")
                session.add_all(stations_to_add)
            await session.commit()
        log.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    else:
        log.error("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ç–∞–Ω—Ü–∏–π –ø—Ä–æ–≤–∞–ª–µ–Ω–∞, —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")
        return

    # --- üêû –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• –º–∞—Ç—Ä–∏—Ü üêû ---
    
    log.info("--- 2/2: –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é –í–°–ï–• –ú–∞—Ç—Ä–∏—Ü (3-*.csv) ---")
    
    # –ò—â–µ–º –í–°–ï —Ñ–∞–π–ª—ã –º–∞—Ç—Ä–∏—Ü 3-
    matrix_files = glob.glob(os.path.join(data_dir_path, '3-*.csv'))
    
    if not matrix_files:
        log.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–∞—Ç—Ä–∏—Ü (3-*.csv) –≤ zdtarif_bot/data/")
        return

    total_routes_added = 0
    
    async with Session() as session:
        for filepath in matrix_files:
            log.info(f"--- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {os.path.basename(filepath)} ---")
            matrix_df = load_kniga_3_matrix(filepath)
            
            if matrix_df is not None and not matrix_df.empty:
                async with session.begin():
                    log.info(f"–î–æ–±–∞–≤–ª—è—é {len(matrix_df)} –º–∞—Ä—à—Ä—É—Ç–æ–≤ (—Å –ø—Ä–æ–ø—É—Å–∫–æ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)...")
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º "upsert" (ON CONFLICT DO NOTHING)
                        # –≠—Ç–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–ø—É—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                        for record in matrix_df.to_dict(orient='records'):
                            stmt = pg_insert(TariffMatrix).values(**record).on_conflict_do_nothing(
                                index_elements=['station_a', 'station_b']
                            )
                            await session.execute(stmt)
                        
                        total_routes_added += len(matrix_df) # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ –ü–û–ü–´–¢–ê–õ–ò–°–¨ –¥–æ–±–∞–≤–∏—Ç—å
                        
                    except Exception as e:
                        log.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ {os.path.basename(filepath)}: {e}", exc_info=True)
                        await session.rollback()
                await session.commit()
            else:
                log.warning(f"–§–∞–π–ª {os.path.basename(filepath)} –ø—Ä–æ–ø—É—â–µ–Ω (–ø—É—Å—Ç–æ–π –∏–ª–∏ –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏).")

    log.info(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –í–°–ï–• –º–∞—Ç—Ä–∏—Ü –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ü–æ–ø—ã—Ç–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {total_routes_added}")
    # --- üèÅ –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø üèÅ ---

    log.info("üéâüéâüéâ == –ú–ò–ì–†–ê–¶–ò–Ø –¢–ê–†–ò–§–ù–û–ô –ë–ê–ó–´ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê! ==")
    log.info("–ü–∞–ø–∫—É zdtarif_bot/data –º–æ–∂–Ω–æ —É–¥–∞–ª—è—Ç—å.")
    
    await engine.dispose()


if __name__ == "__main__":
    asyncio.run(main_migrate())